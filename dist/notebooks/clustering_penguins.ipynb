{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["```\n","TODO:\n","  - Remove train/test split\n","  - Focus on just X\n","```\n","\n","# Clustering Penguins\n","\n","In this notebook, we'll perform clustering on the Penguins dataset using K-means. We'll train on a subset of the data and see how our model generalizes to new, unseen penguins.\n","\n","## 1. Load and clean the dataset.\n","\n","I've done this for you."],"metadata":{"id":"ROVFPUAn0Vt4"}},{"cell_type":"code","source":["from google.colab import drive\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn.decomposition import PCA\n","from sklearn.cluster import KMeans\n","from sklearn.preprocessing import StandardScaler\n","import warnings\n","\n","drive.mount('/content/gdrive')\n","df = pd.read_csv('/content/gdrive/My Drive/datasets/penguins.csv')\n","df = df.dropna()\n","df = df.drop([9, 14])\n","\n","# Inspect the results\n","df.head()"],"metadata":{"id":"AjtRtjEI0cix"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2. Create train/test split\n","\n","Before we begin processing, let's split our data into training and test sets (80/20 split) using sklearn's train_test_split.\n","\n","```python\n","from sklearn.model_selection import train_test_split\n","\n","# Create train/test split (20% test)\n","df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n","\n","print(f\"Training set size: {len(df_train)}\")\n","print(f\"Test set size: {len(df_test)}\")\n","```"],"metadata":{"id":"split_data_section"}},{"cell_type":"code","source":["\n","\n","\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"split_data_code"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 3. One-Hot Encode Categorical Variables\n","\n","We think the penguin `sex` might be useful for our clustering. Let's one-hot encode it for both train and test sets.\n","\n","```python\n","# One-hot encode training data\n","df_train = pd.get_dummies(df_train).drop(\"sex_.\", axis=1, errors=\"ignore\")\n","\n","# One-hot encode test data\n","df_test = pd.get_dummies(df_test).drop(\"sex_.\", axis=1, errors=\"ignore\"\n","```\n","\n","*Inspect both dataframes after you've done this.*"],"metadata":{"id":"etgXhVTZ0srA"}},{"cell_type":"code","source":["\n","\n","\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"r0nLuLSN1Hy4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 4. Scale the features\n","\n","We'll scale the features to standardize them. Remember to fit the scaler on training data only!\n","\n","**Note:** Because this is an unsupervised algorithm, all features in our dataframe become our feature matrix X!\n","\n","```python\n","scaler = StandardScaler()\n","\n","# Fit scaler on training data and transform\n","X_train = pd.DataFrame(\n","    scaler.fit_transform(df_train),\n","    columns=df_train.columns,\n","    index=df_train.index\n",")\n","\n","# Transform test data using the fitted scaler\n","X_test = pd.DataFrame(\n","    scaler.transform(df_test),\n","    columns=df_test.columns,\n","    index=df_test.index\n",")\n","```\n","\n","*Inspect both X_train and X_test after scaling.*"],"metadata":{"id":"dvgMKONF1J2W"}},{"cell_type":"code","source":["\n","\n","\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"9UgAlTrl1sqx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 5. PCA\n","\n","In addition to scaling, we'll reduce the number of features using Principal Component Analysis (PCA). Again, fit only on training data!\n","\n","```python\n","# First, determine optimal number of components using training data\n","pca = PCA(n_components=None)\n","pca_temp = pca.fit(X_train)\n","n_components = sum(pca_temp.explained_variance_ratio_ > 0.1)\n","print(f\"Number of components with variance > 0.1: {n_components}\")\n","\n","# Now fit PCA with optimal components\n","pca = PCA(n_components=n_components)\n","X_train = pd.DataFrame(\n","    pca.fit_transform(X_train),\n","    index=X_train.index\n",")\n","\n","# Transform test data\n","X_test = pd.DataFrame(\n","    pca.transform(X_test),\n","    index=X_test.index\n",")\n","```\n","\n","*Inspect both X_train and X_test, as well as n_components.*"],"metadata":{"id":"7oqmNR8m1ttm"}},{"cell_type":"code","source":["\n","\n","\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"0X3srxNw2Cu7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 6. Determine the Number of Clusters\n","\n","You can either guess the number of clusters or use the elbow method to find the optimal k. We'll use the training data for this.\n","\n","```python\n","inertia = []\n","for k in range(1, 10):\n","    kmeans = KMeans(n_clusters=k, random_state=42).fit(X_train)\n","    inertia.append(kmeans.inertia_)\n","    \n","plt.plot(range(1, 10), inertia, marker=\"o\")\n","plt.xlabel(\"Number of clusters\")\n","plt.ylabel(\"Inertia\")\n","plt.title(\"Elbow Method\")\n","plt.show()\n","```\n","\n","Look for the \"elbow\" in the plot where adding more clusters shows diminishing returns.\n","\n","Pick a number that feels right and assign it to `n_clusters`:\n","\n","```python\n","n_clusters = ...\n","```"],"metadata":{"id":"D8S7bhww2EAl"}},{"cell_type":"code","source":["\n","\n","\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"IEmKTq3S2suo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 7. K-means Clustering\n","\n","Apply K-means clustering with your chosen number of clusters.\n","\n","```python\n","# Fit K-means on training data\n","kmeans = KMeans(n_clusters=n_clusters, random_state=42).fit(X_train)\n","\n","# Get cluster assignments for training data\n","train_clusters = kmeans.labels_\n","\n","# Visualize the training clusters on the first two principal components\n","plt.scatter(X_train.iloc[:, 0], X_train.iloc[:, 1], c=train_clusters, cmap=\"viridis\")\n","plt.xlabel(\"First Principal Component\")\n","plt.ylabel(\"Second Principal Component\")\n","plt.title(f\"K-means Clustering on Training Data (K={n_clusters})\")\n","plt.show()\n","```"],"metadata":{"id":"dJNQctsz2t4H"}},{"cell_type":"code","source":["\n","\n","\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"LdznbIUzU57w"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 8. Predict on Test Set\n","\n","Now let's apply our clustering model to the test set. While we can't evaluate accuracy (no ground truth labels in unsupervised learning!), we can see how the model assigns clusters to new data.\n","\n","```python\n","# Predict clusters for test data\n","y_pred = kmeans.predict(X_test)\n","\n","# Show cluster distribution in test set\n","print(\"Test set cluster distribution:\")\n","print(pd.Series(y_pred).value_counts().sort_index())\n","\n","# Visualize test set predictions\n","plt.figure(figsize=(12, 5))\n","\n","# Plot training data\n","plt.subplot(1, 2, 1)\n","plt.scatter(X_train.iloc[:, 0], X_train.iloc[:, 1], c=train_clusters, cmap=\"viridis\", alpha=0.6)\n","plt.xlabel(\"First Principal Component\")\n","plt.ylabel(\"Second Principal Component\")\n","plt.title(f\"Training Data Clusters (K={n_clusters})\")\n","\n","# Plot test data\n","plt.subplot(1, 2, 2)\n","plt.scatter(X_test.iloc[:, 0], X_test.iloc[:, 1], c=y_pred, cmap=\"viridis\", alpha=0.6)\n","plt.xlabel(\"First Principal Component\")\n","plt.ylabel(\"Second Principal Component\")\n","plt.title(f\"Test Data Predictions\")\n","\n","plt.tight_layout()\n","plt.show()\n","\n","# This clustering could be useful for:\n","# - Identifying different penguin subgroups for conservation efforts\n","# - Understanding natural groupings in the population\n","# - Feature engineering for supervised learning tasks\n","print(\"\\nClustering complete! These groups could represent different penguin subpopulations or behavioral patterns.\")\n","```"],"metadata":{"id":"evaluation_section"}},{"cell_type":"code","source":["\n","\n","\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"evaluation_code"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"x-FN4cX7mKgE"},"execution_count":null,"outputs":[]}]}