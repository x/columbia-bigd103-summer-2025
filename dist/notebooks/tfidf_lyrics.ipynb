{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOK+C3GfKQcZLLCc7XRBWtl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Using TFIDF to Analyze Song Lyrics\n","\n","In this exercise you'll discover what makes a song unique by finding its most distinctive words using TF-IDF.\n","\n","## Assignment Overview\n","\n","You will:\n","1. Load the lyrics dataset into pandas\n","2. Select a target song\n","3. Preprocess the lyrics (turn text into lists of words)\n","4. Calculate TF-IDF to find what words make this song special\n"],"metadata":{"id":"IDTMIBU3-Bbe"}},{"cell_type":"markdown","source":["# Part 1: Setup and import"],"metadata":{"id":"hFoDORmv1PWP"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Se22q_TX94_S"},"outputs":[],"source":["# JUST RUN THIS, no changes needed\n","\n","from google.colab import drive\n","import pandas as pd\n","import math\n","import re\n","\n","drive.mount('/content/gdrive')\n","df = pd.read_csv('/content/gdrive/MyDrive/datasets/lyrics.csv')\n","\n","# Look at the data structure\n","print(df.columns)\n","print(f\"Total songs: {len(df)}\")\n","print(df.head(3))"]},{"cell_type":"markdown","source":["# Part 2: Define our preprocessor"],"metadata":{"id":"fmU0c2oG1TGS"}},{"cell_type":"code","source":["# JUST RUN THIS, no changes needed\n","\n","STOP_WORDS = {\n","    \"a\", \"an\", \"and\", \"are\", \"as\", \"at\", \"be\", \"by\", \"for\", \"from\",\n","    \"has\", \"he\", \"in\", \"is\", \"it\", \"its\", \"of\", \"on\", \"that\", \"the\",\n","    \"to\", \"was\", \"were\", \"will\", \"with\", \"i\", \"you\", \"we\", \"they\",\n","    \"me\", \"my\", \"your\", \"our\", \"their\", \"him\", \"her\", \"she\"\n","}\n","\n","def preprocess(text):\n","    \"\"\"Convert text to a list of lowercase words, removing stop words\"\"\"\n","    # Convert to lowercase first\n","    text = text.lower()\n","\n","    # Split on punctuation and whitespace\n","    tokens = re.split(r\"[,\\.\\!\\?\\s]+\", text)\n","\n","    # Keep only non-empty tokens that aren't stop words\n","    processed_tokens = []\n","    for token in tokens:\n","        if token and token not in STOP_WORDS:\n","            processed_tokens.append(token)\n","\n","    return processed_tokens\n","\n","# Test it\n","test_text = \"Hello! How are you doing today?\"\n","print(preprocess(test_text))  # Should print: ['hello', 'how', 'doing', 'today']"],"metadata":{"id":"AVzpQ6UUuuEA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Part 3: Get Lyrics\n","Write a get_song_lyrics function\n"],"metadata":{"id":"OmMy9Via1Us5"}},{"cell_type":"code","source":["def get_song_lyrics(lyrics_df, artist, title):\n","    # TODO: Your code here!\n","    # 1. Filter to rows where Artist equals artist\n","    # 2. From those rows, filter where Title equals title\n","    # 3. Get the Lyric value (use .iloc[0][\"Lyric\"] or .values[0])\n","    # 4. Handle the case where the song isn't found\n","    pass\n","\n","# Test your function\n","artist = \"Dua Lipa\"  # Change to your choice!\n","title = \"New Rules\"  # Change to your choice!\n","\n","target_lyrics = get_song_lyrics(df, artist, title)\n","print(f\"Found lyrics for {artist} - {title}\")\n","print(f\"First 200 chars: {target_lyrics[:200]}...\")\n"],"metadata":{"id":"nXi7UYQOGODc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","# Part 4: Calculate Term Frequency\n","Write a function to calculate word frequencies"],"metadata":{"id":"1q5fhnYD1XaX"}},{"cell_type":"code","source":["def calculate_term_frequency(text):\n","    term_freq = {}\n","\n","    # FIRST, preprocess the text\n","    processed_text = preprocess(text)\n","\n","    # TODO: Your code here!\n","    # For each word:\n","    #   1. If it IS NOT in term_freq (remember `in term_freq`) set to 1\n","    #   2. If it IS in term_freq increment by 1\n","    #   3. Return the term_freqs\n","\n","    return term_freq\n","\n","# Test your function by running the below\n","tf = calculate_term_frequency(target_lyrics)\n","print(f\"Unique words: {len(tf)}\")\n","print(\"Top 5 words:\", sorted(tf.items(), key=lambda x: x[1], reverse=True)[:5])"],"metadata":{"id":"fXvelOH4-5ZU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","# Part 5: Calculate Document Frequency\n","\n","Write a function that calculates how many documents (songs) the word appears in"],"metadata":{"id":"Hx7hpux11bDK"}},{"cell_type":"code","source":["def calculate_document_frequency(corpus, target_terms):\n","    doc_freq = {}\n","\n","    # FIRST, preprocess all of the corpus into a list of preprocessed list\n","    processed_corpus = []\n","    for doc in corpus:\n","        processed_corpus.append(preprocess(doc))\n","\n","    # TODO: Your Code here!\n","    # We've already preprocessed the corpus for you above!\n","    # Now, for each document in processed_corpus:\n","    #   1. For each word in target_words:\n","    #   2.   Check if word is in the document set\n","    #   3.   If yes, increment doc_freq[word]\n","\n","    return doc_freq\n","\n","# Create corpus and calculate DF\n","corpus = df[\"Lyric\"].tolist()\n","target_words = list(set(tf.keys()))  # Unique words from our target song\n","\n","print(f\"Calculating document frequency for {len(target_words)} words...\")\n","df_counts = calculate_document_frequency(corpus, target_words)"],"metadata":{"id":"sQRuyvj7yBrt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Part 6: Calculate TF-IDF\n","Write a function to calculate the final TF-IDF scores:\n"],"metadata":{"id":"fGfSmR2V1cxW"}},{"cell_type":"code","source":["def calculate_tfidf(term_freq, doc_freq, total_docs):\n","    tfidf = {}\n","\n","    # TODO: Your code here!\n","    # For each word in term_freq:\n","    #   1. Calculate IDF = math.log(total_docs / doc_freq[word])\n","    #   2. Calculate TF-IDF = term_freq[word] * IDF\n","    #   3. Store in tfidf dictionary\n","\n","    return tfidf\n","\n","# Calculate TF-IDF\n","tfidf_scores = calculate_tfidf(tf, df_counts, len(corpus))\n","\n","# Display results\n","sorted_scores = sorted(tfidf_scores.items(), key=lambda x: x[1], reverse=True)\n","print(f\"\\nTop 20 most distinctive words in '{title}':\")\n","for word, score in sorted_scores[:20]:\n","    print(f\"  {word}: {score:.3f}\")"],"metadata":{"id":"BL3a4NJ9GuIc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Part 7: What did we learn?\n","Here's some code to help print out the most common words and the most distinctive words."],"metadata":{"id":"dWuKVNJ81suc"}},{"cell_type":"code","source":["print(\"\\nAnalysis:\")\n","print(f\"Tokens with highest TFIDF scores:\")\n","print(f\"Most common words:')\n","for term, tf_score in sorted(tf.items(), key=lambda x: x[1], reverse=True)[:5]:\n","      print(f\"- {term}: {tf_score}\")\n","\n","print(f\"Most distinctive words:\")\n","for term, tfidf_score in sorted_scores[:5]:\n","      print(f\"- {term}: {tfidf_score}\")\n","\n","print(\"Are they the same? What does this tell us about TF-IDF?\")"],"metadata":{"id":"oi7PlOP16NTg"},"execution_count":null,"outputs":[]}]}