{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1PdBJakbWBmoazPzKzxBqKZ2SY3xHP2M_","timestamp":1739570659957}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Using TF-IDF to Determine What Constitutes an NSF \"Woke DEI Grant\"\n","\n","In this exercise, you'll use Subset TF-IDF to discover what terms characterize grants that were labeled as \"woke\" in a dataset released by the U.S. Senate Commerce Committee.\n","\n","> U.S. Senate Commerce Committee Chairman Ted Cruz (R-Texas) released a database identifying over 3,400 grants, totaling more than $2.05 billion in federal funding awarded by the National Science Foundation (NSF) during the Biden-Harris administration. This funding was diverted toward _questionable projects that promoted Diversity, Equity, and Inclusion (DEI) or advanced neo-Marxist class warfare propaganda._\n","\n","You will:\n","1. Load two datasets of NSF grants\n","2. Preprocess grant descriptions\n","3. Implement Subset TF-IDF to find distinctive terms\n","4. Analyze what makes certain grants distinctive\n","\n","\n","## Background: What is an NSF Grant?\n","\n","The U.S. National Science Foundation (NSF) is an independent agency of the United States federal government that supports fundamental research and education in all the non-medical fields of science and engineering.\n","\n","The NSF funds approximately 25% of all federally supported basic research conducted by the United States' colleges and universities.\n","\n","In some fields, such as mathematics, computer science, economics, and the social sciences, the NSF is the major source of federal backing.\n","\n","---\n","\n","# Pulling and Joining our Datasets\n","\n","For this exercise, we will leverage two datasets which I've already pulled and placed into our shared datasets Google Drive Folder.\n","\n","### Cruz's Dataset of \"Woke\" NSF Grants\n","\n","This database was released as part of the U.S. Senate Commerce Committee's press release and is downloadable from the following page:\n","\n","https://www.commerce.senate.gov/2025/2/cruz-led-investigation-uncovers-2-billion-in-woke-dei-grants-at-nsf-releases-full-database\n","\n","This dataset contains useful information such as recipients and descriptions but is missing details about the \"non-woke\" grants necessary for TF-IDF.\n","\n","### USASpending.gov's Dataset of ALL NSA Assistance Grants in 2022\n","\n","USAspending.gov is the official open data source for federal spending information. Detailed, year-by-year records of all grants since 2008 are available for download:\n","\n","https://www.usaspending.gov/download_center/award_data_archive\n","\n","This dataset is much larger, more detailed, and most importantly, includes the missing information about the non-woke grants needed to build our corpus for TF-IDF.\n","\n","Interesting Columns:\n","\n","- `award_id_fain` - Unique award identifier (join key)\n","- `total_obligated_amount` - Total grant obligated amount\n","- `prime_award_base_transaction_description` - Award description\n","- `recipient_name` - Name of the recipient (often the university name)\n","- `recipient_state_name` - State of the award recipient\n","- `recipient_city_name` - City of the award recipient\n","- `cfda_title` - Catalog of Federal Domestic Assistance title (area of research)\n","\n","**Note:** Because these datasets are large, I focused on just the 2022 grants. If you're interested, I encourage you to extend this exercise by incorporating other years.\n","\n","In this cell we will:\n","- Pull both datasets from our shared Google Drive folder.\n","- Use the \"woke\" dataset to add a new boolean column, `is_woke`, to our dataset. We will use this flag to partion our target subset of documents from the corpus.\n","\n","**I have done the work to pull these datasets and set the `is_work` column.**"],"metadata":{"id":"t0f_iWLJDhWo"}},{"cell_type":"markdown","source":["# Part 1: Setup and import"],"metadata":{"id":"bpUljpTj9C3l"}},{"cell_type":"code","source":["# JUST RUN THIS, no changes needed\n","\n","from google.colab import drive\n","import pandas as pd\n","import math\n","import re\n","from collections import Counter\n","\n","drive.mount('/content/gdrive')\n","\n","# Load the \"woke\" grants dataset\n","woke_grants_df = pd.read_csv(\"/content/gdrive/MyDrive/datasets/woke_grants.tsv\", delimiter=\"\\t\")\n","woke_grant_ids = woke_grants_df.dropna(subset=\"AWARD ID\")[\"AWARD ID\"]\n","\n","# Load all NSF grants from 2022\n","grants_df = pd.read_csv(\"/content/gdrive/MyDrive/datasets/FY2022_049_Assistance_Full_20250109_1.csv\",\n","                        on_bad_lines='skip', low_memory=False)\n","\n","# Add a boolean \"is_woke\" column\n","grants_df[\"is_woke\"] = grants_df[\"award_id_fain\"].isin(woke_grant_ids)\n","\n","# Print dataset info\n","print(f\"Total grants: {len(grants_df)}\")\n","print(f\"Labeled 'woke': {grants_df['is_woke'].sum()}\")\n","print(f\"Percentage: {100 * grants_df['is_woke'].mean():.1f}%\")\n","\n","# Visualize the dataframe\n","grants_df.head()"],"metadata":{"id":"x6xVBAMY908x"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Part 2: Define our preprocessor"],"metadata":{"id":"pdjiclVz9BUn"}},{"cell_type":"code","source":["# JUST RUN THIS, no changes needed\n","\n","STOP_WORDS = {\n","    \"a\", \"an\", \"and\", \"are\", \"as\", \"at\", \"be\", \"by\", \"for\", \"from\",\n","    \"has\", \"he\", \"in\", \"is\", \"it\", \"its\", \"of\", \"on\", \"that\", \"the\",\n","    \"to\", \"was\", \"were\", \"will\", \"with\", \"i\", \"you\", \"we\", \"they\",\n","    \"this\", \"their\", \"our\", \"or\", \"but\", \"if\", \"then\", \"so\", \"such\"\n","}\n","\n","def preprocess(text):\n","    \"\"\"Convert text to a list of lowercase words, removing stop words\"\"\"\n","    if pd.isna(text):\n","        return []\n","\n","    # Convert to lowercase\n","    text = str(text).lower()\n","\n","    # Split on punctuation and whitespace\n","    tokens = re.split(r\"[,\\.\\!\\?\\s\\(\\)\\[\\];:\\\"']+\", text)\n","\n","    # Keep only non-empty tokens that aren't stop words\n","    processed_tokens = []\n","    for token in tokens:\n","        # Remove any remaining punctuation from edges\n","        token = token.strip(\"-/\")\n","        if token and token not in STOP_WORDS and len(token) > 2:\n","            processed_tokens.append(token)\n","\n","    return processed_tokens\n","\n","# Test it\n","test_text = \"This research investigates climate change impacts!\"\n","print(preprocess(test_text))  # Should print: ['research', 'investigates', 'climate', 'change', 'impacts']"],"metadata":{"id":"ROIaDmQS9Et1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Part 3: Get Grant Description by grant_id\n","\n","### Hint\n","`get_grant_description` should look a lot like `get_song_lyrics`:\n","\n","```python\n","def get_song_lyrics(lyrics_df, artist, title):\n","    artist_df = lyrics_df[lyrics_df[\"Artist\"] == artist]\n","    title_df = artist_df[artist_df[\"Title\"] == title]\n","    return title_df['Lyric'].values[0]\n","```\n","\n","Except this time we only need to filer by a single column this time (`grant_id`)."],"metadata":{"id":"HlmfeiUf89WO"}},{"cell_type":"code","source":["def get_grant_description(grants_df, grant_id):\n","    # Input: grants_df is the DataFrame, grant_id is the award ID to find\n","    # Output: Returns the description string (or None if not found)\n","\n","    # TODO: Your code here!\n","    # 1. Filter to rows where award_id_fain equals grant_id\n","    # 2. Get the prime_award_base_transaction_description value\n","    # 3. Handle the case where grant isn't found\n","    pass\n","\n","# Test your function\n","sample_id = grants_df['award_id_fain'].iloc[0]\n","description = get_grant_description(grants_df, sample_id)\n","if description:\n","    print(f\"Sample description: {description[:200]}...\")\n","\n","# Look at some examples of \"woke\" grants\n","print(\"\\nExamples of labeled grants:\")\n","woke_examples = grants_df[grants_df['is_woke'] == True].head(3)\n","for _, row in woke_examples.iterrows():\n","    print(f\"\\n{row['recipient_name']}: {row['prime_award_base_transaction_description'][:150]}...\")"],"metadata":{"id":"KvABpaG79GlI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Part 4: Calculate the Subset **T**erm **F**requency (**TF**-IDF)\n","\n","### Hint\n","\n","Take a look at the slides at:\n","[bigd103.link/slides](bigd103.link/slides)"],"metadata":{"id":"vfMaJ5wC9Zzy"}},{"cell_type":"code","source":["def calculate_subset_term_frequency(subset_descriptions):\n","    # Input: descriptions is a list of nsf grant description (our subset of documents)\n","    # Output: Returns dictionary mapping word -> total count across all descriptions\n","\n","    subset_tf = {}\n","\n","    # TODO: Your code here!\n","    #\n","    # 1. For each grant description:\n","    #      2. preprocess the description\n","    #      3. for each term in the preprocessed description\n","    #          4. add the count of that term to subset_tf\n","\n","    return subset_tf\n","\n","# Calculate TF for \"woke\" grants\n","woke_descriptions = grants_df[grants_df['is_woke'] == True]['prime_award_base_transaction_description'].tolist()\n","print(f\"Calculating term frequency for {len(woke_descriptions)} 'woke' grants...\")\n","\n","woke_tf = calculate_subset_term_frequency(woke_descriptions)\n","print(f\"Unique terms in subset: {len(woke_tf)}\")\n","print(\"Top 10 terms by frequency:\", sorted(woke_tf.items(), key=lambda x: x[1], reverse=True)[:10])"],"metadata":{"id":"QQJTTTlx9ISe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Part 5: Calculate the **D**ocument **F**requency (TF-I**DF**)"],"metadata":{"id":"kB6AueLu9FPZ"}},{"cell_type":"code","source":["def calculate_document_frequency(corpus, target_terms):\n","    # Input: corpus is a list of all nsf grant description strings (all of our documents)\n","    #        target_terms is a set of terms to check\n","    # Output: Returns dictionary mapping term -> number of documents containing it\n","\n","    doc_freq = {}\n","\n","    # TODO: Your code here!\n","    # For each document in corpus:\n","    # 1. Create a new empty list, preprocessed_corpus\n","    # 2. For each document in corpus\n","    #     3. preprocess the document\n","    #     4. append the new preprocessed doc to the preprocessed_corpus\n","    # 2. For each term in target_terms\n","    #     3. For each preprocessed doc in preprocessed_corpus\n","    #         4. If the term is in the doc, increment doc_feq for that term\n","\n","    return doc_freq\n","\n","# Create corpus and calculate DF\n","all_descriptions = grants_df['prime_award_base_transaction_description'].tolist()\n","target_terms = set(woke_tf.keys())\n","\n","print(f\"Calculating document frequency for {len(target_terms)} terms...\")\n","print(f\"Corpus size: {len(all_descriptions)} grants\")\n","\n","df_counts = calculate_document_frequency(all_descriptions, target_terms)"],"metadata":{"id":"ae6mZADk9KDE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Part 6: Calculate Subset TFIDF"],"metadata":{"id":"eC17QCV4_yBw"}},{"cell_type":"code","source":["def calculate_subset_tfidf(subset_tf, doc_freq, total_docs):\n","    # Input: subset_tf is dictionary of term frequencies in the subset\n","    #        doc_freq is dictionary of document frequencies in full corpus\n","    #        total_docs is total number of documents in corpus\n","    # Output: Returns dictionary mapping term -> Subset TF-IDF score\n","\n","    tfidf = {}\n","\n","    # TODO: Your code here!\n","    # For each term in subset_tf:\n","    #   1. Calculate IDF = math.log(total_docs / doc_freq[term])\n","    #   2. Calculate Subset TF-IDF = subset_tf[term] * IDF\n","    #   3. Store in tfidf dictionary\n","\n","    return tfidf\n","\n","# Calculate Subset TF-IDF\n","subset_tfidf_scores = calculate_subset_tfidf(woke_tf, df_counts, len(all_descriptions))\n","\n","# Display results\n","sorted_scores = sorted(subset_tfidf_scores.items(), key=lambda x: x[1], reverse=True)\n","print(f\"\\nTop 30 most terms among 'woke' grants:\")\n","for term, score in sorted_scores[:30]:\n","    print(f\"  {term}: {score:.3f}\")"],"metadata":{"id":"ao1pPWBz9MXK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Bonus: Additional Questions Left to the Reader\n","\n","This concludes this assignment but, in the above code, we've established a toolset to do deeper analysis.\n","\n","Questions that may be worth exploring:\n","\n","1. Do we see different terms when we isolate the dataset to only one area (`cfda_title`)?\n","\n","2. Do terms change for other Biden-Harris presidency years such as 2021, 2023, and 2024?\n","\n","3. How could we scale this methodology into a general form classifier that spans across NSF grants from other presidencies?"],"metadata":{"id":"GK11NpMhf6nB"}},{"cell_type":"code","source":["\n","\n","\n","\n","\n"],"metadata":{"id":"5V-zB_oJ-Y_C"},"execution_count":null,"outputs":[]}]}