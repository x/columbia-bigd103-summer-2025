{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOqLadtV36JtbyiW8fwMdq1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Training Your First Convolutional Neural Network (CNN)\n","\n","In this exercise we're going to train a CNN using PyTorch.\n","\n","I've already put together a cell to do the necessary imports and fetch the training and test data.\n"],"metadata":{"id":"f5MGvtGEJ6LD"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"-0Z8WPKvJ5K_"},"outputs":[],"source":["import torch\n","from torch import nn\n","from torch.utils.data import DataLoader\n","from torchvision import datasets, transforms\n","import torch.nn.functional as F\n","\n","# Define a transform to normalize the data\n","transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n","\n","# Download training data from open datasets.\n","train_data = datasets.MNIST(\n","    root=\"data\",\n","    train=True,\n","    download=True,\n","    transform=transform,\n",")\n","\n","# Download test data from open datasets.\n","test_data = datasets.MNIST(\n","    root=\"data\",\n","    train=False,\n","    download=True,\n","    transform=transform,\n",")"]},{"cell_type":"markdown","source":["## 1. Setup Dataloaders\n","PyTorch has a special object called a DataLoader which we can use to iterate through batches of X and y training and test batches.\n","\n","In neural nets, you need to choose a batch size. You calculate the loss for one batch before doing the backpropagation for that batch.\n","\n","```python\n","batch_size = ...\n","\n","# Create data loaders.\n","train_dataloader = DataLoader(train_data, batch_size=batch_size)\n","test_dataloader = DataLoader(test_data, batch_size=batch_size)\n","```\n","\n","You pick your own batch size here, but I recommend something more than 10 and less than 200."],"metadata":{"id":"1ELOGeKhJ9nc"}},{"cell_type":"code","source":["# YOUR CODE HERE\n","\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"RV4C61-TKCIE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2. Define Your CNN Model\n","\n","In PyTorch, we define a class to make a model. Here's a basic CNN structure suitable for the MNIST dataset.\n","\n","```python\n","# Define model\n","class CNN(nn.Module):\n","    def __init__(self):\n","        super(CNN, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n","        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n","        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n","        self.flatten = nn.Flatten()\n","        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n","        self.fc2 = nn.Linear(128, 10)\n","    \n","    def forward(self, x):\n","        x = self.pool(F.relu(self.conv1(x)))\n","        x = self.pool(F.relu(self.conv2(x)))\n","        x = self.flatten(x)\n","        x = F.relu(self.fc1(x))\n","        x = self.fc2(x)\n","        return x\n","```"],"metadata":{"id":"Xeg6oBMYK_oW"}},{"cell_type":"code","source":["# YOUR CODE HERE\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"Nl4bwybzLMLg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["3. Initialize Your Model, Loss Function, and Optimizer\n","Your model needs to be initialized. Do that. Print it to inspect it.\n","\n","```python\n","model = CNN().to(\"cpu\")\n","print(model)\n","```\n","\n","You'll also need to initialize objects for your loss function (which says how badly a batch performed) and your optimizer (which moves the weights based on the loss).\n","\n","```python\n","loss_fn = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n","```\n"],"metadata":{"id":"S7AwGuZKLM-_"}},{"cell_type":"code","source":["\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"jbbtvvvaLSm2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 4. Train your CNN\n","\n","### 4a. Scaffolding for Epochs\n","One epoch is when you train your entire training dataset and then score your test dataset. You're going to do multiple epochs. Your pick as to how many (but I recommend less than 5 because it can take a while).\n","\n","If you want to train more, you can always re-run this cell!\n","\n","Make sure you initialize your model before we begin.\n","\n","This is the rough scaffolding for the for-loop. We'll fill in the Train and Test sections in the next steps.\n","\n","```python\n","num_epochs = ...\n","for epoch in range(num_epochs):\n","    # Train model for epoch\n","    ...\n","    # Test model for epoch\n","    ...\n","\n","print(\"Model is done!\")\n","```\n","\n","### 4b. Training the Epoch\n","Here's some code for training our epoch. Read through it and try and make sense of it. You should be doing this exactly once per epoch inside the for-loop defined in step 4.\n","\n","```python\n","# Train the epoch (loop over batches of training examples)\n","model.train()\n","for i, (X, y) in enumerate(train_dataloader):\n","    X = X.to(\"cpu\")\n","    y = y.to(\"cpu\")\n","\n","    # Compute prediction error for the batch\n","    pred = model(X)\n","    loss = loss_fn(pred, y)\n","\n","    # Backpropagation\n","    loss.backward()\n","    optimizer.step()\n","    optimizer.zero_grad()\n","\n","    # Log our progress every 100 batches\n","    if i % 100 == 0:\n","        print(f\"loss: {loss.item():>7f}  [{(i+1)*len(X):>5d}/{len(train_dataloader.dataset):>5d}]\")\n","```\n","\n","### 4c. Test the Epoch\n","We test every epoch. Here's the code.\n","\n","```python\n","# Test the epoch (loop over batches of testing examples)\n","model.eval()\n","total_loss = 0\n","num_correct = 0\n","with torch.no_grad():\n","    for X, y in test_dataloader:\n","        X = X.to(\"cpu\")\n","        y = y.to(\"cpu\")\n","        pred = model(X)\n","        total_loss += loss_fn(pred, y).item()\n","        num_correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n","\n","# Evaluate\n","avg_loss = total_loss / len(test_dataloader.dataset)\n","accuracy = num_correct / len(test_dataloader.dataset)\n","print(f\"Test Error: \\n Accuracy: {(100*accuracy):>0.1f}%, Avg loss: {avg_loss:>7f}\")\n","```\n","\n","\n","### 4d. Train Your Model\n","Train your Convolutional Neural Network and track the accuracy and the loss function."],"metadata":{"id":"TZ-Tvku6LTWe"}},{"cell_type":"code","source":["# I FILLED THIS IN FOR YOU\n","\n","num_epochs = 3 # Set this to the number of your choice\n","\n","for epoch in range(num_epochs):\n","    print(f\"Train/Test Epoch Round {epoch + 1}\")\n","    print(f\"------------------------\")\n","\n","    # Train the model (loop over batches of training examples)\n","    model.train()\n","    num_training_samples = len(train_dataloader)\n","    for i, (X, y) in enumerate(train_dataloader):\n","        X = X.to(\"cpu\")\n","        y = y.to(\"cpu\")\n","\n","        # Compute prediction error for the batch\n","        pred = model(X)\n","        loss = loss_fn(pred, y)\n","\n","        # Backpropagation\n","        loss.backward()\n","        optimizer.step()\n","        optimizer.zero_grad()\n","\n","        # Log our progress every 100 batches\n","        if i % 100 == 0:\n","            print(f\"loss: {loss.item():>7f}  [{(i+1)*len(X):>5d}/{num_training_samples:>5d}]\")\n","\n","    # Test the epoch (loop over batches of testing examples)\n","    model.eval()\n","    num_test_samples = len(test_dataloader.dataset)\n","    total_loss = 0\n","    num_correct = 0\n","    with torch.no_grad():\n","        for X, y in test_dataloader:\n","            X = X.to(\"cpu\")\n","            y = y.to(\"cpu\")\n","            pred = model(X)\n","            total_loss += loss_fn(pred, y).item()\n","            num_correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n","\n","    # Evaluate\n","    avg_loss = total_loss / num_test_samples\n","    accuracy = num_correct / num_test_samples\n","    print(f\"Test Error: \\n Accuracy: {(100*accuracy):>0.1f}%, Avg loss: {avg_loss:>7f}\")\n","\n","print(\"Model is done!\")"],"metadata":{"id":"VtavolvtL0aL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 5. Test on Real Images\n","\n","Just like before, let's test on the real images in our `datasets/` folder. Did any do better or worse with this model?\n","\n","```python\n","from torchvision import transforms\n","from PIL import Image\n","from google.colab import drive\n","import matplotlib.pyplot as plt\n","\n","drive.mount('/content/gdrive')\n","\n","# Define the image preprocessing steps\n","preprocess = transforms.Compose([\n","    transforms.Grayscale(num_output_channels=1),  # Convert to grayscale\n","    transforms.Resize((28, 28)),  # Resize to 28x28 pixels\n","    transforms.ToTensor(),  # Convert to tensor\n","    transforms.Normalize((0.5,), (0.5,))  # Normalize to [-1, 1]\n","])\n","\n","# Set the model to eval mode\n","model.eval()\n","\n","# Loop over 10 images\n","for i in range(1, 11):\n","\n","    # Open the image\n","    img_path = f\"/content/gdrive/MyDrive/datasets/mnist_test_sample/img_{i}.jpg\"\n","    img = Image.open(img_path)\n","\n","    # Preprocess the image\n","    img_tensor = preprocess(img)\n","    img_tensor = img_tensor.unsqueeze(0)  # Add batch dimension\n","\n","    # Make prediction\n","    with torch.no_grad():\n","        output = model(img_tensor)\n","        predicted_class = output.argmax(1).item()\n","\n","    # Display the image\n","    plt.figure(figsize=(2, 2))  # Set figure size to 2x2 inches\n","    plt.imshow(img, cmap=\"gray\")\n","    plt.title(\"Input Image\")\n","    plt.axis(\"off\")\n","    plt.show()\n","\n","    # Print the prediction\n","    print(f\"Predicted class: {predicted_class}\")\n","```"],"metadata":{"id":"nFlsOGg0-rL3"}},{"cell_type":"code","source":["# YOUR CODE HERE\n","\n","\n","\n","\n","\n"],"metadata":{"id":"l9VTGKOe-x3g"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Bonus 1\n","\n","If you get this far and we're still working, try changing things about your model to make the accuracy higher.\n","\n","Ideas:\n","- Change the number of epochs\n","- Change the batch size\n","- Change the size of the hidden layer\n","- Add more hidden layers\n","\n"],"metadata":{"id":"mIuN4nZb9Xp7"}},{"cell_type":"markdown","source":["## Bonus 2\n","\n","**Test your own handwriting!**\n","\n","1. Navigate to http://drawmnist.com/\n","2. Draw a number and download it locally.\n","3. Open the 📁 icon on the right side of Colab\n","4. Drag-and-drop your image into the folder\n","5. Test it against your trained model with the code below\n","   ```python\n","   img_path = f\"/content/digit_28x28.jpg\"\n","   img = Image.open(img_path)\n","   \n","   # Preprocess the image\n","   img_tensor = preprocess(img)\n","   img_tensor = img_tensor.unsqueeze(0)  # Add batch dimension\n","   \n","   # Make prediction\n","   with torch.no_grad():\n","       output = model(img_tensor)\n","       predicted_class = output.argmax(1).item()\n","   \n","   # Display the image\n","   plt.figure(figsize=(2, 2))  # Set figure size to 2x2 inches\n","   plt.imshow(img, cmap=\"gray\")\n","   plt.title(\"Input Image\")\n","   plt.axis(\"off\")\n","   plt.show()\n","   \n","   # Print the prediction\n","   print(f\"Predicted class: {predicted_class}\")\n","   ```"],"metadata":{"id":"ygIyaaLp9cc3"}},{"cell_type":"code","source":["# YOUR BONUS CODE HERE\n","\n","\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"VBORQkp48CA2"},"execution_count":null,"outputs":[]}]}