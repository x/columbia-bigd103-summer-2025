{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOoE2GDVazwMmQ0F6miAjLx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Logistic Regression: Predicting College Admissions\n","\n","In this exercise, we'll use logistic regression to predict whether students get admitted to college based on their application data.\n","\n","## What is Logistic Regression?\n","\n","While linear regression predicts continuous values (like passenger numbers), logistic regression predicts categories (like Yes/No, True/False). Perfect for admission decisions!"],"metadata":{"id":"nb_guNUwvNrW"}},{"cell_type":"markdown","source":["## Part 1: Load and Explore the Data\n"],"metadata":{"id":"J2kPQzllxFg2"}},{"cell_type":"code","source":["# JUST RUN THIS\n","\n","from google.colab import drive\n","import pandas as pd\n","\n","drive.mount('/content/gdrive')\n","\n","# Load the data\n","df = pd.read_csv('/content/gdrive/MyDrive/datasets/admission_predict.csv')\n","\n","# Convert \"Chance of Admit\" to a True/False \"Admitted\" column\n","df[\"Admitted\"] = df[\"Chance of Admit \"] > 0.75\n","df.drop(\"Chance of Admit \", axis=1, inplace=True)\n","df.rename(columns={\"LOR \": \"LOR\"}, inplace=True)\n","\n","# Explore the data\n","print(f\"Total applicants: {len(df)}\")\n","print(f\"Admitted: {df['Admitted'].sum()}\")\n","print(f\"Not admitted: {(~df['Admitted']).sum()}\")\n","print(\"\\nColumns:\")\n","print(df.columns.tolist())\n","\n","# Look at a random sample of the data\n","print(\"\\nRandom sample of 5 applicants:\")\n","df.sample(5)"],"metadata":{"id":"zoWR_jG5xG1U"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Part 2: Train-Test Split\n","\n","First, we need to split our data into two sets:\n","\n","- `df_train`: This is the data we'll train the model on.\n","- `df_test`: This is a special set we'll exclude so we can test out how well our model did later.\n","\n"],"metadata":{"id":"Pj79rRfhxQxb"}},{"cell_type":"code","source":["# JUST RUN THIS\n","\n","from sklearn.model_selection import train_test_split\n","\n","# Split the data (I'm doing this for you!)\n","df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n","\n","print(f\"Training set: {len(df_train)} applicants\")\n","print(f\"Test set: {len(df_test)} applicants\")"],"metadata":{"id":"d2cDsXY4xbA1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Part 3: Select Features\n","\n","Now we need to separate our features (X) from our labels (y).\n","\n","**Features (X)**: The information we use to make predictions (test scores, GPA, etc.)\n","\n","**Labels (y)**: What we're trying to predict (Admitted: True/False)\n","\n","### HINTS\n","\n","#### Double Brackets in Pandas\n","\n","When selecting columns in pandas:\n","- Single brackets `df['column']` returns a Series (1D)\n","- Double brackets `df[['column']]` returns a DataFrame (2D)\n","\n","sklearn needs features as a DataFrame (2D), so we use double brackets!\n","\n","```python\n","# Example of single vs double brackets\n","print(\"Single brackets - Series:\")\n","print(type(df['GRE Score']))  # Returns pandas.Series\n","print(\"\\nDouble brackets - DataFrame:\")  \n","print(type(df[['GRE Score']]))  # Returns pandas.DataFrame\n","```\n","\n","#### Returning Multiple Values\n","\n","This function will need to return two values at once and, YES, THAT'S POSSIBLE IN PYTHON!\n","\n","This is done by your return having two values, comma-separated, and assigning the results to two variables, comma-separated.\n","\n","```python\n","def my_function_that_returns_two():\n","    return \"hello world\", 42\n","\n","my_str, my_number = my_function_that_returns_two()\n","```\n","\n","In our case, we'll want our function to return both `X_train` and `X_test`:\n","\n","```python\n","def prepare_features(df_train, df_test):\n","    ...\n","    return X_train, X_test\n","```\n","\n","\n","Once you pick your features (look at the list printed out in Part 1) that you think will predict admission, you can select them each all at once to build the new dataframe.\n","\n","```python\n","X_train = df[['GRE Score', 'University Rating', 'CGPA']]\n","X_test  = df[['GRE Score', 'University Rating', 'CGPA']]\n","return X_train, X_test\n","```\n","\n","\n","Now let's select our features:"],"metadata":{"id":"GZsCrxddxOiN"}},{"cell_type":"code","source":["def prepare_features(df_train, df_test):\n","    # Input: df_train and df_test are DataFrames with all columns\n","    # Output: Returns X_train, X_test (features only, no Serial No. or Admitted)\n","\n","    # TODO: Your code here!\n","    # 1. First, list all the feature columns you want to use\n","    #    Hint: All columns except 'Serial No.' and 'Admitted'\n","    #    You can type them out: feature_cols = ['GRE Score', 'TOEFL Score', ...]\n","    #    Or use: feature_cols = df_train.columns.drop(['Serial No.', 'Admitted']).tolist()\n","\n","    # 2. Create X_train using double brackets\n","    #    X_train = df_train[feature_cols]\n","\n","    # 3. Create X_test the same way\n","    #    X_test = df_test[feature_cols]\n","\n","    # 4. Return both (yes, functions can return multiple values!)\n","    #    return X_train, X_test\n","    pass\n","\n","# Test your function\n","X_train, X_test = prepare_features(df_train, df_test)\n","print(f\"Features shape - Train: {X_train.shape}, Test: {X_test.shape}\")\n","print(f\"Features used: {X_train.columns.tolist()}\")\n","\n","# Check to make sure the same features were picked for X_train and X_test\n","assert(df_train.columns.equals(df_test.columns)"],"metadata":{"id":"4IBSguAoxpPR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Part 4: Extract Labels\n","\n","Now let's get our labels (what we're trying to predict):\n","\n","This is similar to **Part 3** but now we're returning two `Series` instead of two `Dataframes`."],"metadata":{"id":"Lui0uHWVxk_Z"}},{"cell_type":"code","source":["def prepare_labels(df_train, df_test):\n","    # Input: df_train and df_test are DataFrames\n","    # Output: Returns y_train, y_test (just the Admitted column)\n","\n","    # TODO: Your code here!\n","    # 1. Extract the 'Admitted' column from df_train\n","    #    y_train = df_train['Admitted']  # Single brackets for a Series!\n","\n","    # 2. Extract the 'Admitted' column from df_test\n","    #    y_test = df_test['Admitted']\n","\n","    # 3. Return both values\n","    #    return y_train, y_test\n","    pass\n","\n","# Test your function\n","y_train, y_test = prepare_labels(df_train, df_test)\n","print(f\"Training: {y_train.sum()} admitted out of {len(y_train)}\")\n","print(f\"Testing: {y_test.sum()} admitted out of {len(y_test)}\")\n"],"metadata":{"id":"5cO5nikuxsgc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Part 5: Train the Model\n","\n","Time to train our logistic regression model! This is very similar to linear regression:\n","\n","1. Create the model with `model = LogisticRegression()`\n","2. Fit it to the training data with `model.fit(X_train, y_train)`\n","3. Return the trained model\n","\n"],"metadata":{"id":"M_Muw3_yxnOs"}},{"cell_type":"code","source":["from sklearn.linear_model import LogisticRegression\n","\n","def train_logistic_model(X_train, y_train):\n","    # Input: X_train (features), y_train (labels)\n","    # Output: Returns trained model\n","\n","    # TODO: Your code here!\n","    # 1. Create a LogisticRegression model\n","    #    model = LogisticRegression(max_iter=1000)\n","    #    Note: max_iter=1000 gives the model more iterations to converge\n","\n","    # 2. Train the model using the fit method\n","    #    model.fit(X_train, y_train)\n","\n","    # 3. Return the trained model\n","    #    return model\n","    pass\n","\n","# Train the model\n","model = train_logistic_model(X_train, y_train)\n","print(\"Model trained!\")"],"metadata":{"id":"lGGmLCNsxv43"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Part 6: Make Predictions\n","\n","Now let's use our trained model to make predictions on the test set:\n","\n","Use `model.predict(X_test`)."],"metadata":{"id":"sdNJeJq2xxiz"}},{"cell_type":"code","source":["def make_predictions(model, X_test):\n","    # Input: model (trained), X_test (features to predict)\n","    # Output: Returns predictions as a pandas Series\n","\n","    # TODO: Your code here!\n","    # 1. Use the model's predict method to get predictions\n","    #    predictions = model.predict(X_test)\n","    #    This returns a numpy array of True/False values\n","\n","    # 2. Return the Series\n","    #    return predictions_series\n","    pass\n","\n","# Make predictions\n","y_pred = pd.Series(make_predictions(model, X_test))\n","print(f\"Predicted {y_pred.sum()} admissions out of {len(y_pred)} applicants\")\n"],"metadata":{"id":"YFm0v4KOxzaj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Part 7: Evaluate Performance\n","\n","A confusion matrix helps us understand our model's mistakes:\n","\n","You can just run this code, but to understand what's happening here, we want this table:\n","\n","\n","|                   | Predicted Positive (PP) | Predicted Negative (PN) |\n","|-------------------|------------------------|------------------------|\n","| **Actual Positive (P)**   | True Positive (`tp`)      | False Negative (`fn`)     |\n","| **Actual Negative (N)**   | False Positive (`fp`)     | True Negative (`tn`)      |\n","\n","And we have:\n","\n","|                         |  Boolean Series                    |\n","|-------------------------|------------------------------------|\n","| **Actual Positive (P)** | `y_test == True`   |\n","| **Actual Negative (N)** | `y_test == False`  |\n","| **Predicted Positive (PP)** | `y_pred == True`  |\n","| **Predicted Negative (PN)** | `y_pred == False` |\n","\n","And we're use `&` to find the entries where the two Boolean Series created by the two predicates both return True at the same time.\n"],"metadata":{"id":"n0eajIiZx1Vu"}},{"cell_type":"code","source":["# JUST RUN THIS\n","\n","def calculate_confusion_matrix(y_test, y_pred):\n","    # Input: df has 'Admitted' and 'Predicted' columns\n","    # Output: Returns tp, tn, fp, fn\n","    tp = ((y_test == True)  & (y_pred == True)).sum()  # True Positive\n","    tn = ((y_test == False) & (y_pred == False)).sum() # True Negative\n","    fp = ((y_test == False) & (y_pred == True)).sum()  # False Positive\n","    fn = ((y_test == True)  & (y_pred == False)).sum() # False Negative\n","    return tp, tn, fp, fn\n","\n","# Calculate confusion matrix\n","tp, tn, fp, fn = calculate_confusion_matrix(y_test, y_pred)\n","print(\"                  Predicted Positive | Predicted Negative\")\n","print(f\"Actual Positive |{tp:>19d} |{fn:>19d} \")\n","print(f\"Actual Negative |{fp:>19d} |{tn:>19d} \")"],"metadata":{"id":"juGkP4fgx24x"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Part 8: Performance Metrics\n","\n","Now let's calculate how well our model performed:\n","\n","$\n","\\text{Accuracy} = \\frac{tp + tn}{tp + fp + fn + tn} \\\\\n","\\text{Precision} = \\frac{tp}{tp + fp} \\\\\n","\\text{Recall} = \\frac{tp}{tp + fn} \\\\\n","$\n"],"metadata":{"id":"JzPorZHLx_1W"}},{"cell_type":"code","source":["def calculate_metrics(tp, tn, fp, fn):\n","    # Input: Confusion matrix values\n","    # Output: Returns accuracy, precision, recall (3 values!)\n","\n","    # TODO: Your code here!\n","    # Calculate total predictions\n","    # total = tp + tn + fp + fn\n","\n","    # Accuracy: What percentage did we get right?\n","    # accuracy = (tp + tn) / total\n","\n","    # Precision: When we predict admission, how often are we right?\n","    # precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n","\n","    # Recall: Of all actual admissions, what percentage did we catch?\n","    # recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n","\n","    # Return all three metrics\n","    # return accuracy, precision, recall\n","    pass\n","\n","# Calculate metrics\n","accuracy, precision, recall = calculate_metrics(tp, tn, fp, fn)\n","print(f\"Accuracy: {accuracy:.2%} (Overall correctness)\")\n","print(f\"Precision: {precision:.2%} (When we predict admit, how often are we right?)\")\n","print(f\"Recall: {recall:.2%} (Of all admits, what percentage did we identify?)\")"],"metadata":{"id":"bXieBxtPyCeT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Part 9: Analyze Mistakes\n","\n"],"metadata":{"id":"UESu7Vj3yDVp"}},{"cell_type":"code","source":["# JUST RUN THIS\n","\n","# Let's look at where we went wrong\n","false_positives = df_test[(y_test == False) & (y_pred == True)]\n","false_negatives = df_test[(y_test == True)  & (y_pred == False)]\n","\n","print(f\"\\nFalse Positives (predicted admit but rejected):\")\n","if len(false_positives) > 0:\n","    display(false_positives[['GRE Score', 'CGPA', 'Research']].head())\n","\n","print(f\"\\nFalse Negatives (predicted reject but admitted):\")\n","if len(false_negatives) > 0:\n","    display(false_negatives[['GRE Score', 'CGPA', 'Research']].head())\n"],"metadata":{"id":"L9S5u3kqyEoo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Bonus: Feature Importance\n","\n","Which factors matter most for admission?\n","\n","You can use the following code for getting feature importance:\n","\n","```python\n","# Get feature importances (absolute values of coefficients)\n","importances = pd.DataFrame({\n","    'Feature': X_train.columns,\n","    'Importance': abs(model.coef_[0])\n","})\n","importances = importances.sort_values('Importance', ascending=False)\n","\n","print(\"Most important factors for admission:\")\n","print(importances)\n","```\n","\n"],"metadata":{"id":"SSevIjomyGi1"}},{"cell_type":"code","source":["# BONUS CODE HERE\n","\n","\n","\n","\n","\n"],"metadata":{"id":"STqwiew1yPZN"},"execution_count":null,"outputs":[]}]}